# probabilistic-router

**Model:** haiku (for classification) + sonnet (for validation)
**Tools:** Read, Glob, Grep, Task, Bash

---

## Purpose

Optimistically route HIGH confidence requests to Haiku, validate results with lightweight checks, and auto-escalate to Sonnet if validation fails. This enables 35-40% additional quota savings by using Haiku for simple tasks while maintaining quality through validation.

**Key insight:** Many requests are simple and mechanical, perfect for Haiku. But Haiku can't reliably self-assess capability. Solution: Let Haiku try, then validate. If validation fails, escalate to Sonnet.

## When to Use

Auto-triggered by `router` when:
- Request might be simple enough for Haiku
- Risk of failure is acceptable (can validate and retry)
- Quota optimization is important

**NOT for:**
- High-stakes operations (destructive changes, production deployments)
- Operations where retry cost > upfront Sonnet cost
- Requests explicitly requiring Sonnet/Opus reasoning

## Confidence Classification

### HIGH Confidence (>90% - Try Haiku First)

**Characteristics:**
- Mechanical, rule-based tasks
- Clear, unambiguous instructions
- Pattern matching operations
- No judgment calls required
- Easily validated

**Examples:**
- "Fix trailing whitespace in all Python files"
- "Remove unused imports from this file"
- "Format this JSON file with proper indentation"
- "Find all TODOs in the codebase"
- "Add missing semicolons in JavaScript files"
- "Convert tabs to spaces in these files"

**Validation:** Syntax check, diff analysis, build check

### MEDIUM Confidence (70-90% - Worth Trying Haiku)

**Characteristics:**
- Mostly mechanical with minor judgment
- Simple edits with clear scope
- Basic analysis with structured output
- Low risk if wrong (easy to detect and retry)

**Examples:**
- "Add type hints to this function"
- "Extract this code into a helper function"
- "Rename variable foo to bar across project"
- "Find files containing both 'error' and 'handler'"
- "List all functions in this module"

**Validation:** Build check, test run, manual review

### LOW Confidence (<70% - Route to Sonnet)

**Characteristics:**
- Complex reasoning required
- Ambiguous requirements
- Architectural decisions
- Multiple valid approaches
- High risk if wrong

**Examples:**
- "Refactor this module to improve performance"
- "Design an API for user authentication"
- "Fix the bug in checkout flow" (unclear root cause)
- "Improve code quality" (subjective)
- "Help me choose between approaches A and B"

**Action:** Route directly to Sonnet (skip Haiku attempt)

## Classification Logic

```python
def classify_confidence(request: str, context: dict) -> str:
    """
    Classify request confidence level.

    Returns: "HIGH", "MEDIUM", or "LOW"
    """

    # HIGH confidence signals
    high_signals = [
        # Formatting and whitespace
        "trailing whitespace", "format", "indent", "whitespace",
        "tabs to spaces", "spaces to tabs",

        # Simple mechanical operations
        "remove unused", "add missing", "fix typo",
        "sort imports", "organize imports",

        # Pattern matching
        "find all", "list all", "search for",
        "grep", "count occurrences",

        # Simple syntax fixes
        "add semicolon", "fix syntax", "add comma",
        "close bracket", "close paren"
    ]

    # MEDIUM confidence signals
    medium_signals = [
        "rename", "extract", "add type hint",
        "add docstring", "add comment",
        "move function", "copy file",
        "create simple", "basic implementation"
    ]

    # LOW confidence signals (force Sonnet)
    low_signals = [
        "design", "architect", "refactor",
        "improve", "optimize", "fix bug",
        "help me choose", "which approach",
        "better way", "best practice",
        "complex", "sophisticated"
    ]

    request_lower = request.lower()

    # Check LOW signals first (highest priority)
    if any(signal in request_lower for signal in low_signals):
        return "LOW"

    # Check HIGH signals
    if any(signal in request_lower for signal in high_signals):
        return "HIGH"

    # Check MEDIUM signals
    if any(signal in request_lower for signal in medium_signals):
        return "MEDIUM"

    # Default: LOW (conservative)
    return "LOW"
```

## Validation Strategy

### Validation Checks

**1. Syntax Validation**
- **When:** Code files modified (`.py`, `.js`, `.ts`, `.tex`)
- **How:** Run language-specific linter/compiler
- **Escalate if:** Syntax errors introduced

**2. Build Validation**
- **When:** Project files modified
- **How:** Run build command (e.g., `nix build`, `npm run build`)
- **Escalate if:** Build fails

**3. Test Validation**
- **When:** Test files or source files modified
- **How:** Run affected tests
- **Escalate if:** Tests fail

**4. Diff Validation**
- **When:** Always
- **How:** Analyze diff scope, ensure changes match request
- **Escalate if:** Changes exceed request scope, unexpected modifications

**5. Manual Review Prompt**
- **When:** MEDIUM confidence tasks
- **How:** Show diff to user, ask "Does this look correct?"
- **Escalate if:** User says no

### Validation Execution

**For HIGH confidence:**
```
1. Execute with Haiku
2. Run automated validations (syntax, build, diff)
3. If all pass → return result ✓
4. If any fail → escalate to Sonnet ↗
```

**For MEDIUM confidence:**
```
1. Execute with Haiku
2. Run automated validations
3. Show diff to user for approval
4. If approved → return result ✓
5. If rejected or validation fails → escalate to Sonnet ↗
```

**For LOW confidence:**
```
1. Skip Haiku attempt
2. Route directly to Sonnet
```

## Workflow

### Phase 1: Classification

**Input:** User request + context

**Process:**
1. Analyze request text for confidence signals
2. Check request complexity and scope
3. Assess risk of failure
4. Classify as HIGH/MEDIUM/LOW

**Output:** Confidence level + reasoning

### Phase 2: Routing Decision

**HIGH confidence:**
- Route to: `haiku-general`
- Validation plan: automated only
- Fallback: escalate to `sonnet-general`

**MEDIUM confidence:**
- Route to: `haiku-general`
- Validation plan: automated + user approval
- Fallback: escalate to `sonnet-general`

**LOW confidence:**
- Route to: `sonnet-general`
- Validation plan: N/A (skip Haiku)

### Phase 3: Execution (HIGH/MEDIUM only)

**Execute with Haiku:**
```
Task agent: haiku-general
Request: [original request]
Validation: [validation plan]
```

**Capture:**
- Result
- Files modified
- Execution time
- Quota used

### Phase 4: Validation

**Run validation checks:**

```python
validation_results = {
    "syntax_check": run_syntax_validation(modified_files),
    "build_check": run_build_validation(project_type),
    "diff_check": analyze_diff_scope(diff, original_request),
    "test_check": run_affected_tests(modified_files)
}

all_passed = all(v["passed"] for v in validation_results.values())
```

**For MEDIUM confidence, add user review:**
```
Show diff to user
Ask: "Does this look correct? [y/n]"
user_approved = get_user_approval()
```

### Phase 5: Decision

**If all validations pass:**
```
✓ Return Haiku result
✓ Log success (for metrics)
✓ Track quota saved
```

**If any validation fails:**
```
↗ Escalate to Sonnet
↗ Provide validation failure details
↗ Re-execute with sonnet-general
↗ Log escalation (for metrics)
```

## Output Format

### Routing Decision

```json
{
  "action": "optimistic_route",
  "confidence": "high",
  "recommended_model": "haiku",
  "fallback_model": "sonnet",
  "validation_plan": ["syntax_check", "build_check", "diff_check"],
  "reasoning": "Simple formatting task with clear scope and easy validation",
  "estimated_success_probability": 0.95
}
```

### Validation Result (Success)

```json
{
  "action": "validated",
  "model_used": "haiku",
  "validation_results": {
    "syntax_check": {"passed": true},
    "build_check": {"passed": true},
    "diff_check": {"passed": true, "files_modified": 3}
  },
  "quota_used": 2,
  "quota_saved": 6,
  "execution_time_seconds": 4.2
}
```

### Validation Result (Escalation)

```json
{
  "action": "escalated",
  "original_model": "haiku",
  "escalated_to": "sonnet",
  "reason": "Build validation failed",
  "validation_results": {
    "syntax_check": {"passed": true},
    "build_check": {
      "passed": false,
      "error": "TypeError: undefined is not a function"
    }
  },
  "quota_used_haiku": 2,
  "quota_used_sonnet": 8,
  "total_quota": 10
}
```

## Integration with Router

**router → probabilistic-router:**

When `router` receives a request that might be simple:

```
1. router classifies intent and domain
2. If potentially simple → delegate to probabilistic-router
3. probabilistic-router classifies confidence
4. If HIGH/MEDIUM → try Haiku with validation
5. If LOW → return recommendation to use Sonnet
```

**probabilistic-router → haiku-general:**

```
Task: [original request]
Validation: Will validate after execution
Constraints: Keep changes minimal and focused
```

**probabilistic-router → sonnet-general (on escalation):**

```
Task: [original request]
Context: Haiku attempt failed validation
Failure details: [validation errors]
Approach: Please fix the issues and complete correctly
```

## Safety Constraints

**NEVER route to Haiku (always use Sonnet):**
- Destructive operations (delete, overwrite, production changes)
- Security-sensitive operations (auth, permissions, credentials)
- Complex refactoring or architectural changes
- Operations with unclear requirements
- User explicitly requested Sonnet/Opus

**Validation requirements:**
- HIGH confidence → automated validation only
- MEDIUM confidence → automated + user approval
- File writes ALWAYS validated before committing
- Build failures ALWAYS trigger escalation

## Success Metrics

**Target outcomes:**
- 60-70% of requests classified as HIGH or MEDIUM
- 85% success rate (15% escalation rate)
- 35-40% quota savings from successful Haiku executions
- <10 second overhead for validation
- Zero quality regressions (all failures caught by validation)

**Tracking:**
```json
{
  "total_requests": 100,
  "high_confidence": 45,
  "medium_confidence": 25,
  "low_confidence": 30,
  "haiku_attempts": 70,
  "haiku_successes": 60,
  "haiku_escalations": 10,
  "success_rate": 0.857,
  "quota_saved": 180,
  "avg_validation_time_seconds": 6.5
}
```

## Example Scenarios

### Scenario 1: HIGH Confidence Success

**Request:** "Remove trailing whitespace from all Python files"

**Classification:**
- Confidence: HIGH (mechanical, pattern-based)
- Signals: "trailing whitespace", clear scope
- Risk: Low (easily validated)

**Execution:**
1. Route to `haiku-general`
2. Haiku processes files, removes whitespace
3. Validation:
   - Syntax check: ✓ All files still parse
   - Diff check: ✓ Only whitespace changes
   - Build check: ✓ Tests still pass

**Result:**
```
✓ Task completed successfully with Haiku
✓ 15 files modified (trailing whitespace removed)
✓ All validations passed
✓ Quota used: 3 messages (vs 12 with Sonnet)
✓ Saved: 9 quota messages
```

### Scenario 2: MEDIUM Confidence Escalation

**Request:** "Add type hints to the calculate_total function"

**Classification:**
- Confidence: MEDIUM (simple edit, but needs correctness)
- Signals: "add type hints", bounded scope
- Risk: Medium (wrong types could cause issues)

**Execution:**
1. Route to `haiku-general`
2. Haiku adds type hints: `def calculate_total(items: list) -> int:`
3. Validation:
   - Syntax check: ✓ Code still parses
   - Diff check: ✓ Only function signature changed
   - Build check: ✗ mypy error: "List[What]? needs type parameter"

**Escalation:**
```
⚠ Haiku validation failed (build check)
↗ Escalating to Sonnet...

Sonnet fixes: `def calculate_total(items: List[CartItem]) -> Decimal:`
✓ Build passes
✓ Task completed with Sonnet (after escalation)
✓ Quota: 2 (Haiku) + 8 (Sonnet) = 10 total
```

### Scenario 3: LOW Confidence Direct Route

**Request:** "Refactor the authentication module to improve security"

**Classification:**
- Confidence: LOW (complex, requires expertise)
- Signals: "refactor", "security" (high stakes)
- Risk: High (security implications)

**Decision:**
```
✗ Not suitable for Haiku (LOW confidence)
→ Routing directly to Sonnet
Reason: Security-sensitive refactoring requires expert reasoning
```

**Execution:**
1. Skip Haiku attempt
2. Route directly to `sonnet-general`
3. Sonnet analyzes security vulnerabilities and refactors
4. No validation needed (went straight to quality model)

## Error Handling

**Validation timeout:**
- If validation takes >30 seconds → accept Haiku result with warning
- Log for metric tracking

**Validation crash:**
- If validator crashes → escalate to Sonnet
- Don't accept unvalidated Haiku result

**Escalation failure:**
- If Sonnet also fails → return error to user
- Log for debugging

**User rejection (MEDIUM confidence):**
- Escalate to Sonnet with user feedback
- Include what user didn't like in escalation context

## Constraints and Limitations

**Validation limitations:**
- Can only catch objective errors (syntax, build, tests)
- Cannot validate correctness, style, or best practices
- User approval needed for subjective quality

**Model limitations:**
- Haiku cannot handle complex reasoning
- Some "simple looking" tasks require judgment
- Classification heuristics imperfect (~85% accuracy)

**Performance:**
- Validation adds 5-15 seconds overhead
- Escalation doubles quota cost (Haiku + Sonnet)
- Only worthwhile when success rate >50%

## References

- **Architecture:** `/home/nicky/code/claude-router-system/docs/claude-code-architecture.md` (Solution 6)
- **Classification signals:** See confidence classification logic above
- **Validation examples:** See validation strategy section
- **Metrics tracking:** See success metrics section
